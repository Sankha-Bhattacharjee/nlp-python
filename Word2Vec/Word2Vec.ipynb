{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba1ff72",
   "metadata": {},
   "source": [
    "### Limitations of BOW and TF-IDF model\n",
    "<li>Semantic information is not stored. Even in TF-IDF model we only give importance to uncommon words.</li>\n",
    "<li>There is a chance to overfitting your model. Overfitting is when your model is too closely tied with training data and does well with training data but performs poorly with new data.</li>\n",
    "\n",
    "### Word2Vec model\n",
    "<li>In this model each word is represented as a vector of 32 or more dimensions instead of a single number</li>\n",
    "<li>Relation between separate words are preserved</li>\n",
    "<br>\n",
    "<b>Steps:</b>\n",
    "<ol>\n",
    "    <li>Scrape through huge dataset like the whole wikipedia </li>\n",
    "    <li>Create a whole matrix with all the unique words in the dataset. The matrix represents the occurance relationship between models</li>\n",
    "    <li>Split the matrix in two thin matrices</li>\n",
    "    <li>We have the model</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c567cb",
   "metadata": {},
   "source": [
    "##  ***Building Word2Vec model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4cad94b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import urllib\n",
    "import bs4 as bs\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508356d",
   "metadata": {},
   "source": [
    "### Fetching Data from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4337cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = urllib.request.urlopen('https://en.wikipedia.org/wiki/Climate_change').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b6c7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs.BeautifulSoup(source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "897e4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "\n",
    "for paragraph in soup.find_all('p'):\n",
    "    text+=paragraph.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6910ea",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "379375d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r'\\[[0-9]*\\]',' ', text)\n",
    "text = re.sub(r'\\s+',' ', text)\n",
    "text = text.lower()\n",
    "text = re.sub(r'[@#\\$\\%\\*\\(\\)\\{\\}\\[\\]\\+]',' ', text)\n",
    "text = re.sub(r'\\d',' ', text)\n",
    "text = re.sub(r'\\s+',' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07481d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)\n",
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ed85cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af9bb47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word for word in sentences[i] if word not in english_stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839df754",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13659ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, min_count=1) # min_count=we will ignore all the words with frequency less than this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b99c334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word to index dict\n",
    "words = model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb2763e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.32197624e-02,  1.57655235e-02,  2.24995753e-03, -7.62303127e-03,\n",
       "       -9.01957601e-03, -2.79170088e-02,  1.03491498e-02,  3.80639434e-02,\n",
       "       -2.19229292e-02, -1.49719482e-02, -2.00697407e-02, -2.95138005e-02,\n",
       "       -1.50051983e-02, -3.62161594e-03,  1.03122853e-02, -1.58294979e-02,\n",
       "        1.03270565e-03, -1.94836296e-02, -2.54769321e-03, -3.16581875e-02,\n",
       "       -4.89174668e-03,  2.87487195e-03,  1.91747099e-02, -5.39449835e-03,\n",
       "       -1.40529461e-02, -2.23496929e-03, -9.67528298e-03, -1.17570357e-02,\n",
       "       -9.01293103e-03,  1.34216975e-02,  3.16833667e-02, -1.17369015e-02,\n",
       "       -6.28552458e-04, -1.83756743e-02, -6.11896487e-03,  2.50285044e-02,\n",
       "        1.23198098e-02,  8.58989137e-04,  8.69853393e-05, -2.68974639e-02,\n",
       "        1.19003719e-02, -2.02892404e-02, -1.32058430e-02, -9.65767889e-04,\n",
       "        1.06649883e-02, -8.94327741e-03, -6.87225815e-03,  6.30669203e-03,\n",
       "        6.97216718e-03, -1.10534881e-03,  8.60343967e-03, -2.78188139e-02,\n",
       "        3.14615015e-03,  9.74235497e-03, -2.26770490e-02,  2.20563356e-02,\n",
       "        2.11784802e-02, -3.60254757e-03, -2.10912284e-02, -2.46039126e-03,\n",
       "        1.00211892e-02, -2.40501962e-04,  6.29182300e-03, -3.03209061e-03,\n",
       "       -1.04563106e-02,  2.12224126e-02,  6.84365677e-03,  1.04256403e-02,\n",
       "       -2.35438272e-02,  9.94728599e-03, -2.19928031e-03,  1.27106654e-02,\n",
       "        2.68942565e-02,  3.66930198e-03,  1.96302198e-02,  1.78899933e-02,\n",
       "       -1.24265281e-02,  4.95004351e-04, -8.85066669e-03,  5.90046751e-04,\n",
       "       -1.36039709e-03, -1.05607985e-02, -1.76540273e-03,  1.47451451e-02,\n",
       "        3.04447790e-03, -9.37232375e-03, -5.13364701e-03,  2.08772477e-02,\n",
       "        1.54027445e-02,  3.83182918e-03,  3.02059669e-02,  1.59146003e-02,\n",
       "       -8.50520749e-03, -1.01381307e-02,  3.04587558e-02,  1.50637692e-02,\n",
       "        6.11556601e-03, -2.40120161e-02,  1.06282011e-02, -7.13991746e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector of word global\n",
    "model.wv['global']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9590784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('climate', 0.8907241821289062),\n",
       " (',', 0.8898768424987793),\n",
       " ('.', 0.8662092089653015),\n",
       " ('may', 0.8575513362884521),\n",
       " ('heat', 0.8561801910400391),\n",
       " ('global', 0.8485167026519775),\n",
       " ('change', 0.838651180267334),\n",
       " ('emissions', 0.8366113305091858),\n",
       " ('also', 0.8334764838218689),\n",
       " ('greenhouse', 0.8318421840667725)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar to word 'warming' i.e. the words that have appeared to the word 'warming' in this context\n",
    "model.wv.most_similar('warming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37635c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
